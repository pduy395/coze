{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-4-mini',\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are an expert relevance ranker. Given a list of documents and a query, your job is to determine how relevant each document is for answering the query. Your output is JSON, which is a list of documents.  Each document has two fields, content and score.  relevance_score is from 0.0 to 100.0. Higher relevance means higher score.\"},\n",
    "      {\"role\": \"user\", \"content\": f\"Query: {query} Docs: {docs}\"}\n",
    "    ]\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 23 16:10:28 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 522.06       Driver Version: 522.06       CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  Off |\n",
      "|  0%   54C    P8    22W / 450W |   7980MiB / 24564MiB |     10%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     42672    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     49296    C+G   ...51.105\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     52564    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     52764    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     53116    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     53816    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     53824    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     54276    C+G   ...dows\\System32\\Taskmgr.exe    N/A      |\n",
      "|    0   N/A  N/A     55432    C+G   ...e\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     56880    C+G   ...oft OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     63552    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('pkshatech/GLuCoSE-base-ja', device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Memory: 63.83 GB\n",
      "Available Memory: 25.33 GB\n",
      "Used Memory: 38.50 GB\n",
      "Memory Usage: 60.3%\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Get the memory details\n",
    "memory_info = psutil.virtual_memory()\n",
    "\n",
    "# Print the total, available, and used memory\n",
    "print(f\"Total Memory: {memory_info.total / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Available Memory: {memory_info.available / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Used Memory: {memory_info.used / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Memory Usage: {memory_info.percent}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
